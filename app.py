import streamlit as st
import json
import random
import traceback
import re
import io
from docx import Document

class NeuroExpertMaster:
    def __init__(self, matrix_data):
        try:
            # –°–¢–´–ö–û–í–ö–ê: –ë–µ—Ä–µ–º –¥–∞–Ω–Ω—ã–µ –Ω–∞–ø—Ä—è–º—É—é –∏–∑ –ø–∞–º—è—Ç–∏ –°—Ç—Ä–∏–º–ª–∏—Ç–∞
            self.lib = matrix_data
            
            def deep_find(data, target):
                if isinstance(data, dict):
                    if target in data: return data[target]
                    for v in data.values():
                        found = deep_find(v, target)
                        if found: return found
                return None
            
            self.rv = deep_find(self.lib, "risk_verification")
            self.sr = deep_find(self.lib, "suicide_risk")
            self.nv = deep_find(self.lib, "neuro_vectors")
            # st.toast ‚Äî —ç—Ç–æ –º–∞–ª–µ–Ω—å–∫–æ–µ –≤—Å–ø–ª—ã–≤–∞—é—â–µ–µ –æ–∫–Ω–æ –≤ –°—Ç—Ä–∏–º–ª–∏—Ç–µ
            st.toast("‚úÖ –ü–†–ò–õ–û–ñ–ï–ù–ò–ï –ó–ê–ü–£–©–ï–ù–û")
        except Exception as e: 
            st.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏: {e}")
            self.lib = {}

    def apply_gender(self, text, gender, is_endo=False):
        if isinstance(text, list):
            forbidden = "(–æ—Ä–≥–∞–Ω–∏–∫–∞)" if is_endo else "(—ç–Ω–¥–æ–≥–µ–Ω)"
            # 1. –°–Ω–∞—á–∞–ª–∞ –í–´–ö–ò–î–´–í–ê–ï–ú –≤—Å—ë —á—É–∂–¥–æ–µ:
            filtered = [str(t) for t in text if forbidden not in str(t).lower()]
            # 2. –ê —Ç–µ–ø–µ—Ä—å –≤—ã–±–∏—Ä–∞–µ–º —Ç–æ–ª—å–∫–æ –∏–∑ —Ç–æ–≥–æ, —á—Ç–æ –æ—Å—Ç–∞–ª–æ—Å—å:
            text = random.choice(filtered) if filtered else random.choice(text)

        text = str(text)
        is_fem = (gender == '–∞')
        if is_fem: text = text.replace("–µ–Ω{g}", "–Ω–∞").replace("{g}", "–∞")
        else: text = text.replace("{g}", "")

        fem_map = {"–∏–Ω–µ—Ä—Ç–µ–Ω": "–∏–Ω–µ—Ä—Ç–Ω–∞", "–∞–∫—Ç–∏–≤–µ–Ω": "–∞–∫—Ç–∏–≤–Ω–∞", "—Å–ø–æ–∫–æ–µ–Ω": "—Å–ø–æ–∫–æ–π–Ω–∞", "–æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω": "–æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∞",
                   "–∞–¥–µ–∫–≤–∞—Ç–µ–Ω": "–∞–¥–µ–∫–≤–∞—Ç–Ω–∞", "–Ω–µ—É—Å—Ç–æ–π—á–∏–≤": "–Ω–µ—É—Å—Ç–æ–π—á–∏–≤–∞", "–∑–∞—Ç–æ—Ä–º–æ–∂–µ–Ω": "–∑–∞—Ç–æ—Ä–º–æ–∂–µ–Ω–∞",
                   "–ø–æ–¥–≤–∏–∂–µ–Ω": "–ø–æ–¥–≤–∏–∂–Ω–∞", "–∑–∞–≤–∏—Å–∏–º": "–∑–∞–≤–∏—Å–∏–º–∞", "—Ä–µ–∑–≤": "—Ä–µ–∑–≤–∞", "–¥–æ—Å—Ç—É–ø–µ–Ω": "–¥–æ—Å—Ç—É–ø–Ω–∞"}
        if is_fem:
            for m, f in fem_map.items(): text = re.sub(rf"\b{m}\b", f, text)
            text = text.replace("–ø–∞—Ü–∏–µ–Ω—Ç ", "–ø–∞—Ü–∏–µ–Ω—Ç–∫–∞ ")
        else: text = text.replace("–ø–∞—Ü–∏–µ–Ω—Ç–∫–∞", "–ø–∞—Ü–∏–µ–Ω—Ç")

        text = text.replace("['", "").replace("']", "").replace("'", "").replace('"', "")
        text = re.sub(r"\(.*?\)", "", text).replace("..", ".").replace(" ,", ",").replace(",,", ",").replace(". ,", ". ")
        sentences = [s.strip().capitalize() for s in text.split('.') if s.strip()]
        return ". ".join(sentences) + "." if sentences else ""

    def run(self, code_str, pr_in, t_in):
        try:
            head, s_raw = code_str.split('/')
            raw_typ = head.rstrip('–º–∂'); gen = '–∞' if head.endswith('–∂') else ''
            s = [int(x) for x in s_raw if x.isdigit()][:10]
            while len(s) < 10: s.append(0)

            st_log = self.lib.get("status_logic", {}); cl_bases = self.lib.get("clinical_bases", {})
            concl = cl_bases.get("conclusions", self.lib.get("conclusions", {}))
            adj_lib = self.lib.get("phenomenology_adjustments", {})
            intros = st_log.get("intros", {})

            typ_key = raw_typ if raw_typ in intros else ('0' if raw_typ.startswith('0') else raw_typ)
            is_endo = (typ_key == "8"); is_organ = typ_key in ["1","2","3","4","5"]
            is_norm_logic = typ_key.startswith('0') and sum(s) < 10
            presets = [p.strip() for p in pr_in.split(',') if p.strip()]; tags = [t.strip().lower() for t in t_in.split(',') if t.strip()]

            # --- 1. –ü—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π —Å—Ç–∞—Ç—É—Å ---
            st_raw = [intros.get(typ_key, intros.get("0", "")), cl_bases.get(raw_typ if raw_typ in cl_bases else str(round(sum(s) / 10)), "")]
            # –î–æ–±–∞–≤–ª—è–µ–º –ü–ê –≤ —Å—Ç–∞—Ç—É—Å, –µ—Å–ª–∏ –µ—Å—Ç—å —Ç–µ–≥
            if "–ø–∞" in tags: st_raw.append(self.lib.get("tags", {}).get("–ø–∞", ""))
            for p in presets:
                # –ò—â–µ–º –Ω–∞–¥—Å—Ç—Ä–æ–π–∫—É –∏ –∫–∞–∫ –≤–≤–µ–ª (—Ä–µ—Ç–∏–∫), –∏ –∫–∞–ø—Å–æ–º (–†–ï–¢–ò–ö) –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π
                p_data = adj_lib.get(p, adj_lib.get(p.upper(), {}))
                st_raw.append(p_data.get("status", ""))
            for t in tags:
                if t != "–ø–∞": st_raw.append(self.lib.get("tags", {}).get(t, ""))
            if hasattr(self, 'sr') and self.sr:
                # –ë–µ—Ä–µ–º —Ñ—Ä–∞–∑—É –ø–æ —Ç–∏–ø—É –ø—Ä–æ—Ñ–∏–ª—è (3, 8, 0*) –∏–ª–∏ –¥–µ—Ñ–æ–ª—Ç "0"
                s_phrase = self.sr.get(typ_key, self.sr.get("0", ""))
                if s_phrase:
                    st_raw.append(s_phrase)
            status_text = ". ".join([self.apply_gender(p, gen, is_endo).rstrip('.') for p in st_raw if p]) + "."

            # --- 2. –†–ï–ó–£–õ–¨–¢–ê–¢–´ ---
            f_res = []
            f_keys = ["attention", "visual_gnosis", "spatial", "dynamic_praxis", "afferent_praxis", "cube", "calculation", "speech", "memory", "thinking"]
            for i, k in enumerate(f_keys):
                f_res.append(self.apply_gender(self.lib.get("functions", {}).get(k, {}).get(str(s[i]), [""]), gen, is_endo))
                for p in presets:
                    res_adj = adj_lib.get(p, {}).get("results", "")
                    if res_adj and ((i == 3 and p in ["–ê–ø—Ä–¥–∏–Ω", "–ª–µ–≤—Ä–µ–≥", "–ø—Ä–∞–≤—Ä–µ–≥"]) or (i == 7 and p in ["–ê—Å–µ–Ω—Å", "–ê—Å–µ–º", "–ê–∞—Ñ"])):
                        f_res.append(self.apply_gender(res_adj, gen, is_endo))

            # --- 3. –ó–ê–ö–õ–Æ–ß–ï–ù–ò–ï ---
            final = []
            # –í–µ–∫—Ç–æ—Ä –î–µ–ø—Ä–µ—Å—Å–∏–∏/–ì–æ—Ä—è
            if (typ_key == "9" or any(p.startswith('–î') for p in presets)) and self.nv:
                final.append(self.apply_gender(self.nv.get("9", ""), gen, is_endo))

            # –°–ê–ú–ú–ê–†–ò (–°–∏–Ω—Ç–µ–∑ –ø–æ –±–∞–ª–ª–∞–º)
            summ_list = concl.get("functional_summaries", [""])
            s_sum = sum(s); s_idx = 0 if s_sum <= 7 else (1 if s_sum <= 15 else 2)
            if is_norm_logic: s_idx = 0
            final.append(self.apply_gender(summ_list[s_idx if s_idx < len(summ_list) else -1], gen, is_endo))

            # --- –°–ò–ù–¢–ï–ó (–¶–ï–ú–ï–ù–¢) ---
            # 1. –ë–µ—Ä–µ–º –¥–∞–Ω–Ω—ã–µ. –ï—Å–ª–∏ —ç—Ç–æ —Å–ª–æ–≤–∞—Ä—å (—Å—Ç–∞—Ä—ã–π –≤–∏–¥) - –ø—Ä–µ–≤—Ä–∞—â–∞–µ–º –≤ —Å–ø–∏—Å–æ–∫ –∑–Ω–∞—á–µ–Ω–∏–π
            raw_synth = concl.get("synthesis", [])
            synth_list = list(raw_synth.values()) if isinstance(raw_synth, dict) else raw_synth

            if synth_list and s_sum >= 3:
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ—Ä–∑–∏–Ω—É (0, 1 –∏–ª–∏ 2)
                s_idx = 1 if is_endo else (0 if s_sum <= 7 else (1 if s_sum <= 15 else 2))
                # –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π –∑–∞–±–æ—Ä —Ñ—Ä–∞–∑—ã (—á—Ç–æ–±—ã –Ω–µ –±—ã–ª–æ IndexError)
                target_phrase = synth_list[s_idx if s_idx < len(synth_list) else -1]
                final.append(self.apply_gender(target_phrase, gen, is_endo))

            # --- –í–ï–ö–¢–û–†–´ (–ê–¥–¥–∏—Ç–∏–≤–Ω–∞—è —Å–±–æ—Ä–∫–∞: –õ–∏—á–∏–Ω–∞ + –í–°–ï –¢–µ–≥–∏ + –ü–ê) ---
            v_parts = []

            # 1. –ë–∞–∑–æ–≤—ã–π –≤–µ–∫—Ç–æ—Ä (–¢–û–õ–¨–ö–û –¥–ª—è –∏–∑–±—Ä–∞–Ω–Ω—ã—Ö 8, 7, 9)
            if is_endo or (typ_key in ["9", "7"]):
                base_v = self.nv.get(typ_key, "")
                if base_v: v_parts.append(base_v)

            # 2. –ê –¢–ï–ì–ò –î–û–°–¢–£–ü–ù–´ –í–°–ï–ú (–í—ã—Ä–æ–≤–Ω—è–ª –≤–ª–µ–≤–æ!)
            for t in tags:
                if t in self.nv and t != "–ø–∞":
                    v_parts.append(self.nv[t])

            # 3. –ü–ê –¢–û–ñ–ï –î–õ–Ø –í–°–ï–• (–í—ã—Ä–æ–≤–Ω—è–ª –≤–ª–µ–≤–æ!)
            if "–ø–∞" in tags and "–ø–∞" in self.nv:
                v_parts.append(self.nv["–ø–∞"])

            # 4. –°–ë–û–†–ö–ê –ò –ß–ò–°–¢–ö–ê (–í—ã—Ä–æ–≤–Ω—è–ª –≤–ª–µ–≤–æ!)
            if v_parts:
                v_clean = [random.choice(p) if isinstance(p, list) else p for p in v_parts]
                final.append(self.apply_gender(" ".join(v_clean), gen, is_endo))

            # –§–ê–ö–¢–û–†–´ –° –ë–£–°–¢–ï–†–ê–ú–ò
            if not is_norm_logic:
                f_active = []; f_p = concl.get("factors", {})
                b1 = 3 if any(p in ["–Ω", "–ê–ø–∞—Ç", "–∞—Å—Ç–µ"] for p in presets) and is_organ else 0
                b2 = 3 if any(p in ["–ê—Å–µ–Ω—Å", "–ê–∞—Ñ", "–ê–∞–∫", "–ê—Å–µ–º", "–ê–ø—Ä–∫–∏–Ω", "–ê–ø—Ä–∫–æ–Ω", "–ê–≥–Ω–ü", "–ê–≥–Ω–õ", "–Ω–µ–≥–ª–µ–∫—Ç"] for p in presets) and is_organ else 0
                b3 = 3 if any(p in ["–ø—Ä–∞–≤—Ä–µ–≥", "–ª–µ–≤—Ä–µ–≥", "–ê—ç—Ñ", "–ê–ø—Ä–¥–∏–Ω"] for p in presets) and is_organ else 0

                if (s[0] + s[6] + b1 >= 3): f_active.append(self.apply_gender(f_p.get('neurodynamic', ''), gen, is_endo).rstrip('.') + " (I –±–ª–æ–∫)")
                if (s[1] + s[2] + s[5] + b2 >= 3): f_active.append(self.apply_gender(f_p.get('spatial', ''), gen, is_endo).rstrip('.') + " (II –±–ª–æ–∫)")
                if (s[3] + s[9] + b3 >= 3): f_active.append(self.apply_gender(f_p.get('regulatory', ''), gen, is_endo).rstrip('.') + " (III –±–ª–æ–∫)")

                if f_active:
                    res_f = f_active[0]
                    for n_f in f_active[1:]: res_f = res_f.rstrip(".") + ", " + n_f[:1].lower() + n_f[1:]
                    for p in presets:
                        concl_adj = adj_lib.get(p, {}).get("conclusion", "")
                        if concl_adj: res_f = res_f.rstrip(".") + ". " + self.apply_gender(concl_adj, gen, is_endo)
                    final.append(res_f)

            # –†–ï–ó–Æ–ú–ï –ò –í–ê–†–ò–ê–¢–ò–í–ù–´–ô –†–ò–°–ö
            final.append(self.apply_gender(concl.get("personality_emotional_resume", {}).get("stable" if is_norm_logic else "unstable", ""), gen, is_endo))
            if self.rv:
                risk_opts = self.rv.get(typ_key, self.rv.get("0", ""))
                final.append(self.apply_gender(risk_opts, gen, is_endo))

            return f"–ü–°–ò–•–û–õ–û–ì–ò–ß–ï–°–ö–ò–ô –°–¢–ê–¢–£–°:\n{status_text}\n\n–†–ï–ó–£–õ–¨–¢–ê–¢–´:\n{' '.join(f_res)}\n\n–ó–ê–ö–õ–Æ–ß–ï–ù–ò–ï:\n" + "\n".join([p.strip() for p in final if p.strip()])
            return final_res

        except Exception: 
            return traceback.format_exc()

# –ó–∞–≥—Ä—É–∑–∫–∞ JSON-–∞–∫–∫—É–º—É–ª—è—Ç–æ—Ä–∞
@st.cache_data
def load_matrix():
    with open('expert_matrix.json', 'r', encoding='utf-8-sig') as f:
        return json.load(f)

matrix = load_matrix()

st.set_page_config(page_title="NeuroExpert Web", layout="wide")

import base64

# 1. –§–£–ù–ö–¶–ò–Ø –ö–û–î–ò–†–û–í–ê–ù–ò–Ø –ö–ê–†–¢–ò–ù–ö–ò (–ß—Ç–æ–±—ã –≤—à–∏—Ç—å –≤ HTML)
def get_base64_image(image_path):
    try:
        with open(image_path, "rb") as img_file:
            return base64.b64encode(img_file.read()).decode()
    except:
        return ""

# –ö–æ–¥–∏—Ä—É–µ–º —Ç–≤–æ–π –º–æ–∑–≥
img_base64 = get_base64_image("brain3.jpg")

# 2. –ï–î–ò–ù–´–ô –ë–õ–û–ö: –ì–†–ê–î–ò–ï–ù–¢ + –ú–û–ó–ì + –¢–ï–ö–°–¢ (–í–°–Å –í –û–î–ù–û–ú –°–¢–ê–ö–ê–ù–ï)
st.markdown(f"""
    <div style="
        background: linear-gradient(90deg, #0e1117 0%, #1c1f26 100%); 
        padding: 20px; 
        border-radius: 15px; 
        border-left: 5px solid #FF4B4B; 
        display: flex; 
        align-items: center; 
        gap: 20px;
        margin-bottom: 25px;
    ">
        <img src="data:image/jpeg;base64,{img_base64}" 
             style="width: 60px; height: 60px; border-radius: 10px; object-fit: cover;">
        <div>
            <h1 style="color: #ffffff; margin: 0; font-family: 'Segoe UI'; font-size: 2.2em; line-height: 1.1;">
                <span style="color: #FF4B4B;">Neuro</span>Expert
            </h1>
            <p style="color: #808495; font-style: italic; margin-top: 4px; font-size: 0.95em;">
                –ö–æ–º–ø–ª–µ–∫—Å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ —Å–∏–Ω–¥—Ä–æ–º–∞–ª—å–Ω–æ–≥–æ –Ω–µ–π—Ä–æ–ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
            </p>
        </div>
    </div>
""", unsafe_allow_html=True)

# 3. –ì–ê–ô–î - –í –°–ê–ô–î–ë–ê–† (–ß–¢–û–ë–´ –ù–ï –ü–û–†–¢–ò–õ –ú–û–ù–û–õ–ò–¢)
with st.sidebar:
    st.markdown("---")
    try:
        with open("AppGuide.pdf", "rb") as f:
            st.download_button("üìö –°–ö–ê–ß–ê–¢–¨ –ì–ê–ô–î (PDF)", f, "NeuroExpert_Guide.pdf", "application/pdf")
    except:
        pass

# --- 2. –õ–ï–í–ê–Ø –ü–ê–ù–ï–õ–¨ (–°–ê–ô–î–ë–ê–†) ---
with st.sidebar:
    # –¢–≤–æ–∏ –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è –º–æ–∑–≥–æ–≤
    c1, c2, c3 = st.columns([1, 2, 1]) 
    with c2:
        try:
            st.image("brain2.jpg", width=150)
        except:
            st.write("üß†")
            
    st.header("üìã –ü–∞—Å–ø–æ—Ä—Ç")
    
    # –ö–Ω–æ–ø–∫–∞ —Å–±—Ä–æ—Å–∞ (–æ–¥–Ω–∞, –≤ —Å–∞–π–¥–±–∞—Ä–µ)
    if st.button("‚ôªÔ∏è –°–ë–†–û–°–ò–¢–¨ –í–°–Å", type="secondary"):
        reset_app()
    
    fio = st.text_input("–§–ò–û", "–ò–≤–∞–Ω–æ–≤ –ò.–ò.", key="fio_input")
    age = st.number_input("–í–æ–∑—Ä–∞—Å—Ç", 1, 110, 65, key="age_input")
    p_type = st.selectbox("–¢–∏–ø", ["0*", "0+", "00", "0—Ç", "0-", "0000", "0", "0—Å–æ–Ω", "1", "2", "3", "4", "5", "7", "8", "9", "9–≥—ç"], key="profile_select")
    p_gen = st.radio("–ü–æ–ª", ["–º", "–∂"], horizontal=True)

    st.markdown("---") # –ß–µ—Ä—Ç–∞
    
    # –ü–ï–†–ï–ù–ï–°–õ–ò –°–ü–ò–°–ö–ò –°–Æ–î–ê (–î–õ–Ø –£–î–û–ë–°–¢–í–ê –ò –°–ú–ê–†–¢–§–û–ù–ê)
    adj_keys = list(matrix.get("phenomenology_adjustments", {}).keys())
    presets = st.multiselect("üõ† –ù–∞–¥—Å—Ç—Ä–æ–π–∫–∏", adj_keys, key="adj_ms")
    tag_keys = list(matrix.get("tags", {}).keys())
    selected_tags = st.multiselect("üè∑ –¢–µ–≥–∏", tag_keys, key="tags_ms")

# --- 3. –¶–ï–ù–¢–†–ê–õ–¨–ù–û–ï –ü–û–õ–ï (–§–£–ù–ö–¶–ò–ò) ---
st.subheader("üìä –§—É–Ω–∫—Ü–∏–∏ (0-5)")
f_names = ["–í–Ω–∏–º–∞–Ω–∏–µ", "–ó—Ä–∏—Ç.–ì–Ω–æ–∑–∏—Å", "–ü—Ä–æ—Å—Ç—Ä.–ì–Ω–æ–∑–∏—Å", "–î–∏–Ω.–ü—Ä–∞–∫—Å–∏—Å", "–ö–∏–Ω.–ü—Ä–∞–∫—Å–∏—Å", "–ö–æ–Ω—Å—Ç—Ä.–ü—Ä–∞–∫—Å–∏—Å", "–°—á–µ—Ç", "–†–µ—á—å", "–ü–∞–º—è—Ç—å", "–ú—ã—à–ª–µ–Ω–∏–µ"]
scores = []

# –£–ë–†–ê–õ–ò –ö–û–õ–û–ù–ö–ò: —Ç–µ–ø–µ—Ä—å –ø–æ–ª–∑—É–Ω–∫–∏ –∏–¥—É—Ç –°–¢–†–û–ì–û 1, 2, 3... –±–µ–∑ –ø—É—Ç–∞–Ω–∏—Ü—ã –Ω–∞ —Å–º–∞—Ä—Ç–µ
for i, name in enumerate(f_names):
    scores.append(st.slider(f"{i+1}. {name}", 0, 5, 0, key=f"s_{i}"))

# --- 4. –ö–ù–û–ü–ö–ê –ì–ï–ù–ï–†–ê–¶–ò–ò (–í –°–ê–ú–û–ú –ù–ò–ó–£) ---
if st.button("üöÄ –°–ì–ï–ù–ï–†–ò–†–û–í–ê–¢–¨ –ü–†–û–¢–û–ö–û–õ"):
    # –¢–≤–æ–π –¥–≤–∏–∂–æ–∫ –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –∑–¥–µ—Å—å...
    full_code = f"{p_type}{p_gen}/{''.join(map(str, scores))}"
    
    # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç —ç–Ω–¥–∂–∏–Ω–∞ –ø—Ä—è–º–æ –∑–¥–µ—Å—å
    engine = NeuroExpertMaster(matrix)
    
    # –ü—Ä–æ–≥–æ–Ω—è–µ–º —á–µ—Ä–µ–∑ RUN
    report = engine.run(full_code, ",".join(presets), ",".join(selected_tags))
    
    st.markdown("### –ò—Ç–æ–≥–æ–≤—ã–π —Ç–µ–∫—Å—Ç:")
    st.text_area("", report, height=500)
    
    # –í–û–†–î-–ü–†–ò–ù–¢–ï–†
    doc = Document()
    doc.add_paragraph(f"–ü–†–û–¢–û–ö–û–õ: {fio}")
    doc.add_paragraph(report)
    bio = io.BytesIO()
    doc.save(bio)
    st.download_button("üì• –°–∫–∞—á–∞—Ç—å .docx", bio.getvalue(), f"{fio}.docx")
